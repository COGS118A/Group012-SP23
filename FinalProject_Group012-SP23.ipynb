{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# COGS 118A - Final Project"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### PLEASE GRADE THE OTHER FILE \n",
    "\n",
    "\n",
    "# Names\n",
    "\n",
    "- Antara Sengupta\n",
    "- Ryan Harsono\n",
    "- Alyssa Fleschner\n",
    "- Josue Sanchez"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Abstract \n",
    "In this project, our goal is to build a model that can predict the stage of Alzheimer’s disease within an individual based upon MRI scan images. In the specific dataset that we are working with, there are 4 levels of severity that are presented: none, very mild, mild, and moderate. This dataset also provides us with both the original and augmented images of the scans. The MRI scans are separated into 4 sets based upon severity, and we will use a set of these images and their respective classifications to train our model, and then test our model with the images we set aside to use as our testing data. We also may use methods like cross-validation to increase accuracy, but due to the large size of our data set, we may only use a subset of the data in our model development process. Our objective is to develop an algorithm that can gauge the severity of Alzheimer’s disease within a patient using their MRI scan, and we will use our chosen database to train and test our model, and test performance and predictive accuracy through methods such as confusion matrices, AUC-ROC and others that we find fit.\n",
    "\n",
    "\n",
    " __NB:__ this final project form is much more report-like than the proposal and the checkpoint. Think in terms of writing a paper with bits of code in the middle to make the plots/tables"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Background\n",
    "Alzheimer's disease is a neurodegenerative disorder that causes memory loss, loss of cognitive abilities and change in behavior. Magnetic Resonance Imagining (MRI’s) is an imaging technique utilized to visualize internal parts of the brain. MRI’s detect the abnormalities in the brain that are associated with diagnosing Alzheimer’s disease. With our study patients experiencing Alzheimer’s disease, their cortical thickness diminishes as well as the hippocampus breaking down which can deteriorate rapidly with age. Typically, we see this degeneration process in ages 60 and above, however, there are cases of Alzheimer’s starting in a person’s 30’s. With our dataset on Kaggle</a>[<sup>[1]</sup>](#reference_1), we aim to explore how image segmentation and advanced processing techniques can detect early onset symptoms, identify significant discrepancies through brain image processing, and monitor the progression of the disease. With our model, images of MRI scans will be trained and tested to help improve accuracy and prevent overfitting of our different stages of Alzheimer’s. We aim to determine different levels of Alzheimer's disease through image classification of MRI scans. Other models </a>[<sup>[2]</sup>](#reference_2) extract relevant features from the MRI scans with dementia patients and utilized metrics, such as, ROC-AUC to differentiate between healthy or not. Deep learning models contribute to the idea of medical analysis with image processing and can create a change in how we approach neurological diseases. Our study aims to utilize deep learning models with advanced image processing in order to detect early onset symptoms of Alzheimer's. In efforts to improve medical image analysis and lead to a better diagnosis plus identifying where patients need help. From the Debugger Cafe, </a>[<sup>[3]</sup>](#reference_3) our Alzheimers disease model can relate to how they are utilizing brain MRI classification using PyTorch EfficientNetB0. The idea is to implement the EfficientNetB0 to classify and conclude MRI scans for Alzheimers detection. We also included PyImageSearch, </a>[<sup>[4]</sup>](#reference_4), to focus our convolutional neural network models (CNN) on developing image classification for Alzheimers. "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Problem Statement\n",
    "\n",
    "The problem that we will be tackling in the duration of this project is the determination and diagnosis of levels of Alzheimer’s disease within patients by using image classification of their MRI scans. Our objective is to develop a model that will be able to identify whether a given individual has none, very mild, mild or moderate levels of dementia based upon their MRI scan. We will use image data from our chosen database to train and test our model. Some of the metrics and techniques we may use in our model development are feature extraction and feature engineering, KNN and decision tree algorithms to assist us with classification tasks, and cross-validation, ROC-AUC and correlation matrices to analyze the accuracy and predictive validity of our model. In the feature engineering process, we may opt for methods such as PCA to create feature vectors which we could then proceed to use other techniques on to propel our classification algorithm. In this project, we are dealing explicitly with classifying images based on four specific classifications: (1) none, (2) very mild, (3) mild, and (4) moderate. We will not be dealing with any subjectivity in diagnosis or any gray area that lies outside of these four specific classifications that have been provided to us by our dataset. The dataset we have chosen is extremely large, having over forty-thousand images, and although we may not use all the data for this project in the sake of efficiency, time and complexity, we will still have a very large dataset to work with which inherently has benefits in aspects such as reproducibility. By having our project focus on classifying images into four specific categories, we ensure the quantifiable nature of our problem, while also establishing the measurability by utilizing various techniques and metrics to approach our problem that has been taught to us throughout the quarter."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data\n",
    "\n",
    "\n",
    "If the data cleaning process is very long (e.g., elaborate text processing) consider describing it briefly here in text, and moving the actual clearning process to another notebook in your repo (include a link here!).  The idea behind this approach: this is a report, and if you blow up the flow of the report to include a lot of code it makes it hard to read.\n",
    "\n",
    "https://www.kaggle.com/datasets/uraninjo/augmented-alzheimer-mri-dataset\n",
    "\n",
    "- 33984 rows × 2 columns is the size of the dataset, 2 variables, 33984 observations\n",
    "- The observation consist of two variables 1 being the image, and the 2nd being the label\n",
    "- The critical variable would be the second column as it is the labels we will need to predict and train our data with supervised learning\n",
    "\n",
    "![Alzheimer-Class Model V1](Alzheimer-Class_Model_V1/alzheimer-classification-2-1.png)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Proposed Solution\n",
    "\n",
    "In this section, clearly describe a solution to the problem. The solution should be applicable to the project domain and appropriate for the dataset(s) or input(s) given. Provide enough detail (e.g., algorithmic description and/or theoretical properties) to convince us that your solution is applicable. Make sure to describe how the solution will be tested.  \n",
    "\n",
    "If you know details already, describe how (e.g., library used, function calls) you plan to implement the solution in a way that is reproducible.\n",
    "\n",
    "If it is appropriate to the problem statement, describe a benchmark model<a name=\"sota\"></a>[<sup>[3]</sup>](#sotanote) against which your solution will be compared.\n",
    "\n",
    "\n",
    "Since our goal is to perform image classification, we will implement a variety of neural networks using the libraries that can be found with python, which is designed for computer vision and image processing tasks. While libraries provides many classification models, we are specifically interested in the most popular ones, which include: TensorFlow Sequential EfficientNet GoogLeNet ResNet VGG These were selected from a combination of sources</a>[<sup>[2]</sup>](#reference_2)</a>[<sup>[3]</sup>](#reference_3)</a>[<sup>[4]</sup>](#reference_4). Each of the above neural networks were revolutionary in their time and have been proven to perform well when processing images. We would also like to compare their performances to a simple convolutional neural network with minimal layers. All of the models models will be implemented on the train/test splits we determine for our dataset, and their performances will be measured using a standardized loss function."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluation Metrics\n",
    "\n",
    "Propose at least one evaluation metric that can be used to quantify the performance of both the benchmark model and the solution model. The evaluation metric(s) you propose should be appropriate given the context of the data, the problem statement, and the intended solution. Describe how the evaluation metric(s) are derived and provide an example of their mathematical representations (if applicable). Complex evaluation metrics should be clearly defined and quantifiable (can be expressed in mathematical or logical terms).\n",
    "\n",
    "To measure the accuracy of our models, we plan to simply compare the predicted labels and the actual labels of our classifications. We then plan to produce accuracy percentages for each of the four classes in our dataset. Additionally, we plan to compare the losses of each model using cross entropy loss, a common neural network metric that measures the performance of classification models. The ideal model would have high accuracy and low loss."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Results\n",
    "\n",
    "You may have done tons of work on this. Not all of it belongs here. \n",
    "\n",
    "Reports should have a __narrative__. Once you've looked through all your results over the quarter, decide on one main point and 2-4 secondary points you want us to understand. Include the detailed code and analysis results of those points only; you should spend more time/code/plots on your main point than the others.\n",
    "\n",
    "If you went down any blind alleys that you later decided to not pursue, please don't abuse the TAs time by throwing in 81 lines of code and 4 plots related to something you actually abandoned.  Consider deleting things that are not important to your narrative.  If its slightly relevant to the narrative or you just want us to know you tried something, you could keep it in by summarizing the result in this report in a sentence or two, moving the actual analysis to another file in your repo, and providing us a link to that file.\n",
    "\n",
    "### Subsection 1\n",
    "\n",
    "You will likely have different subsections as you go through your report. For instance you might start with an analysis of the dataset/problem and from there you might be able to draw out the kinds of algorithms that are / aren't appropriate to tackle the solution.  Or something else completely if this isn't the way your project works.\n",
    "\n",
    "### Subsection 2\n",
    "\n",
    "Another likely section is if you are doing any feature selection through cross-validation or hand-design/validation of features/transformations of the data\n",
    "\n",
    "### Subsection 3\n",
    "\n",
    "Probably you need to describe the base model and demonstrate its performance.  Maybe you include a learning curve to show whether you have enough data to do train/validate/test split or have to go to k-folds or LOOCV or ???\n",
    "\n",
    "### Subsection 4\n",
    "\n",
    "Perhaps some exploration of the model selection (hyper-parameters) or algorithm selection task. Validation curves, plots showing the variability of perfromance across folds of the cross-validation, etc. If you're doing one, the outcome of the null hypothesis test or parsimony principle check to show how you are selecting the best model.\n",
    "\n",
    "### Subsection 5 \n",
    "\n",
    "Maybe you do model selection again, but using a different kind of metric than before?\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Discussion\n",
    "\n",
    "### Interpreting the result\n",
    "\n",
    "OK, you've given us quite a bit of tech informaiton above, now its time to tell us what to pay attention to in all that.  Think clearly about your results, decide on one main point and 2-4 secondary points you want us to understand. Highlight HOW your results support those points.  You probably want 2-5 sentences per point.\n",
    "\n",
    "### Limitations\n",
    "\n",
    "Are there any problems with the work?  For instance would more data change the nature of the problem? Would it be good to explore more hyperparams than you had time for?   \n",
    "\n",
    "### Ethics & Privacy\n",
    "\n",
    "\n",
    "In our dataset, we may have ethical concerns of patient confidentiality because we are analyzing patients with Alzheimer. These datasets can be collected from Kaggle, however, the images included are mainly MRI and will not reveal any personal information on the patients. All data will minimize any potentially harmful consequences and only be utilized to help predict results/analysis. While we are aware that we are dealing with sensitive data in this project, such as medical images and scans, we are solely using data that is readily available to the public on a site like Kaggle, and opted to not use data from specific medical/neurological research sites that warranted request applications in order to access some of their datasets. These measures taken by us will prevent a multitude of ethical violations, along with the fact that there is no patient identification information provided along with the dataset and the images. For the duration of this project, we will continue to be mindful of ethics and privacy with each step we take.\n",
    "\n",
    "### Conclusion\n",
    "\n",
    "Reiterate your main point and in just a few sentences tell us how your results support it. Mention how this work would fit in the background/context of other work in this field if you can. Suggest directions for future work if you want to."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Footnotes\n",
    "\n",
    "\n",
    "<a name=\"reference_1\"></a>1.[^](#Uraninjo):\"Augmented Alzheimer MRI Dataset.\" Kaggle, 2021: https://www.kaggle.com/datasets/uraninjo/augmented-alzheimer-mri-dataset<br>\n",
    "\n",
    "<a name=\"reference_2\"></a>2.[^](#ScienceDirect):\"A machine learning approach for the detection of dementia based on MRI scans\",Science Direct, 2018:https://www.sciencedirect.com/science/article/pii/S0939388918301181\n",
    "\n",
    "<a name=\"reference_3\"></a>3.[^](#DebuggerCafe): \"Brain MRI Classification using PyTorch EfficientNet-B0\", Debugger Cafe: https://debuggercafe.com/brain-mri-classification-using-pytorch-efficientnetb0/\n",
    "\n",
    "<a name=\"reference_4\"></a>4.[^](#PyImage):\"PyTorch Image Classification with Pre-trained Networks\", PyImageSearch: https://pyimagesearch.com/2021/07/26/pytorch-image-classification-with-pre-trained-networks/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
